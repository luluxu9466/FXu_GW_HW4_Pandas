{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The cell below creates a reference to the csv file and stores it in a variable called `resume_path`. Then it creates two sets `REQUIRED_SKILLS` with a list of words as required skills and `DESIRED_SKILLS` with a list of words as desired skills. These two sets will be interated through to look through the resume and find words in these sets._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The cell below defines a function of loading the file that takes in the file path. Read the resume file as text using the `with` statement. The function reads the contents of the resume, use `lower` to convert all words to lower case, use `split` to remove and trailing punctuation so only words remain, and return the cleaned list of words. \n",
    "How is this function defined? What does it take in, how does it work, and what does it return?]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The cell below calls the function `load_file(filepath)` while passing the resume_path as filepath. It returns a cleaned list (as defined in the function) of words in the resume csv and stores the list in variable `word_list`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below first creates a set of unique words from the resume using `set()`. The set is created for operations between other sets (intersections, subtractions, etc.). Then it iterates through the list of words in the resume csv and add them to the set `resume` if it is not already in the set. Create a set from `string.punctuation` to use in the difference operation. Subtracting the punctuation set from the resume set takes out all words that contains only  punctuation from the set `resume`. Lastly, create a new line with `\\n` and print out the cleaned set after removing punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'contributing', 'stein', 'learning,', 'forecasting', 'pandas', 'excel.', 'api', 'front-end', 'in', 'git/github', '#', 'd3', 'creating', 'leaflet.js', 'tableau,', 'html/css,', 'vba', 'python', 'tables', 'microsoft', 'data', 'excel,', 'visualizations', 'analytics', 'the', 'mysql', 'using', 'media', 'files', 'hadoop,', 'mining,', 'designing', 'camp', 'business', 'to', 'and', 'pivot', '*', 'intelligence', '##', 'cloud', 'basic', 'statistics', 'working', 'writing', 'big', 'skills', 'modeling', 'experience', 'algorithms', 'apis.', 'r,', 'visualization', 'interests', 'mongodb', 'web', 'open-source', 'analyze', 'advanced', 'n.', 'hadoop', 'machine', 'databases', 'developing', 'statistics,', 'interactions,', 'd3,', 'html,', 'python,', 'learning', 'from', 'bootstrap,', 'performing', 'social', 'boot', 'sql,', 'mining', 'scripts', 'software', 'apps', 'tableau', 'javascript,', 'css,', 'graduate', 'aws', 'sets', 'education', 'with', 'frank'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'contributing', 'stein', 'learning,', 'pandas', 'forecasting', 'excel.', 'api', 'front-end', 'in', 'git/github', 'd3', 'creating', 'leaflet.js', 'tableau,', 'html/css,', 'vba', 'python', 'tables', 'microsoft', 'data', 'excel,', 'visualizations', 'analytics', 'the', 'mysql', 'using', 'media', 'files', 'hadoop,', 'mining,', 'designing', 'camp', 'business', 'to', 'and', 'pivot', 'intelligence', '##', 'cloud', 'basic', 'statistics', 'working', 'writing', 'big', 'skills', 'modeling', 'experience', 'algorithms', 'apis.', 'r,', 'visualization', 'interests', 'mongodb', 'web', 'open-source', 'analyze', 'advanced', 'n.', 'hadoop', 'machine', 'databases', 'developing', 'statistics,', 'interactions,', 'd3,', 'html,', 'python,', 'learning', 'from', 'bootstrap,', 'performing', 'social', 'boot', 'sql,', 'mining', 'scripts', 'software', 'apps', 'tableau', 'javascript,', 'css,', 'graduate', 'aws', 'sets', 'education', 'with', 'frank'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below first performs set intersections, and then use list comprehensions to remove punctuations and stop words.\n",
    "* Using the set intersection between the cleaned set (no punctuation) and the set of required skills, we find all of the words from the resume that match the required skills. Using the set intersection between the cleaned set (no punctuation) and the set of desired skills, we find all of the words that match the desired skills. \n",
    "* The punctuation cleaning function work the same as the set subtraction method in the previous cell- it removes all words that only contains punctuations. The character punctuation cleaning, however, removes the punctuations within a word (for example, it removes the \",\" in \"sql,\").\n",
    "** The list comprehension for word punctuation cleaning removes all words that only contains punctuations and returns words that contain characters other than puncutations. It iterates through all words in the word_list and uses filtering criteria `word not in string.punctuation`.\n",
    "** The list comprehension for character punctuation cleaning iterates through all characters in each word in the word_list and removes any character that is a punctuation. The filtering criteria is whether the character in the word is a punctuation (`char not in string.punctuation`).\n",
    "** The list comprehension for clean stop words iterates through all words in the word_list and removes all words that are also in the list of stop_words. The filtering criteria is `word not in stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'statistics', 'mysql'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `word_count` dictionary with default values equal to zero with words in word_list as key values. `for loop` to iterate through all words in the word_list. With every occurence of a `word`, add 1 to the current count of that `word` in `word_count`. `word_count[word]` refers to the count value associated with `word`. \n",
    "Using the for loop and collections.Counter yield the same counts for each word. However, with the for loop, the dictionary is organized by the order of the keys (i.e. words in this case) in the word_list. By using Counter() the dictionary word_counter is organized by the values (i.e. word counts in this case) in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First initialize a list for sorted words. Sort the dictionary by the values of word count. `sorted()` is a function that creates a sorted list of keys from the dictionary `word_count` by `word_count.get`, which yields the values (word counts) in the dictionary, by `reverse=True` order (descending order). We are only interested in the top 10 words so we only take the first 10 elements in the list created by sorted() by using `[:10]`. Then we use a for loop to iterate through all the words in the first 10 elements of the list created by sorted() and print out these words and there respective counts.\n",
    "To get rid of the blank token, we could add blank, or '', to our stop_words list and perform the clean stop words function to remove the blank word from our word_list. We could also iterate through the word list and remove all blank tokens (for example `while '' in some_list: some_list.remove('')`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token:                      Count: 4\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "sorted(word_count, key=word_count.get, reverse=True)[:10]\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
